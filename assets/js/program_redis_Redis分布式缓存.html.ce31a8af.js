"use strict";(self.webpackChunkxwblog=self.webpackChunkxwblog||[]).push([[4899],{6262:(i,s)=>{s.A=(i,s)=>{const e=i.__vccOpts||i;for(const[i,a]of s)e[i]=a;return e}},1426:(i,s,e)=>{e.r(s),e.d(s,{comp:()=>P,data:()=>q});var a=e(641);const n=e.p+"assets/img/image-20210725144240631.7abcc356.png",l=e.p+"assets/img/image-20210725151319695.383ba413.png",t=e.p+"assets/img/20250810579591.086f5a84.png",p=e.p+"assets/img/20250810161616.50a49b93.png",r=e.p+"assets/img/image-20210725151654046.687b4639.png",d=e.p+"assets/img/image-20210725151729118.23604bbf.png",h=e.p+"assets/img/image-20210725151940515.c420b57c.png",g=e.p+"assets/img/image-20210725152037611.b3ed472d.png",o=e.p+"assets/img/image-20210725152222497.8db5b133.png",c=e.p+"assets/img/image-20210725152700914.1f67d74d.png",k=e.p+"assets/img/20250810181515.e7c3d92c.png",u=e.p+"assets/img/image-20210725153201086.cd2dbdd2.png",m=e.p+"assets/img/image-20210725153524190.082b02db.png",b=e.p+"assets/img/image-20210725153715910.5408000a.png",v=e.p+"assets/img/image-20210725153937031.07473e57.png",A=e.p+"assets/img/image-20210725154155984.6d931d16.png",f=e.p+"assets/img/image-20210725154216392.12ae8610.png",y=e.p+"assets/img/image-20210725154405899.d20cdc8f.png",F=e.p+"assets/img/image-20210725154528072.8c652abf.png",B=e.p+"assets/img/image-20210725154632354.c06b6469.png",R=e.p+"assets/img/20250810195151.991d66fe.png",_=e.p+"assets/img/image-20210725154816841.a2a74bb2.png",x=e.p+"assets/img/image-20210725155747294.cc93dabb.png",O=e.p+"assets/img/image-20210725155820320.a690583a.png",D=e.p+"assets/img/image-20210725161007099.044311be.png",C=e.p+"assets/img/image-20210725162224058.65f19ed6.png",E=e.p+"assets/img/image-20210725162441407.6a30ec58.png",w=(0,a.Lk)("h1",{id:"redis持久化分布式缓存",tabindex:"-1"},[(0,a.Lk)("a",{class:"header-anchor",href:"#redis持久化分布式缓存"},[(0,a.Lk)("span",null,"Redis持久化分布式缓存")])],-1),I=(0,a.Lk)("p",null,"AOF|RDB、主从搭建、哨兵集群、分片集群根本学不完。。。",-1),z=(0,a.Fv)('<h2 id="_1-redis持久化" tabindex="-1"><a class="header-anchor" href="#_1-redis持久化"><span>1 Redis持久化</span></a></h2><p>单机的Redis存在四大问题：</p><figure><img src="'+n+'" alt="image-20210725144240631" tabindex="0" loading="lazy"><figcaption>image-20210725144240631</figcaption></figure><h3 id="_1-1-rdb持久化" tabindex="-1"><a class="header-anchor" href="#_1-1-rdb持久化"><span>1.1 RDB持久化</span></a></h3><p>RDB全称Redis Database Backup file（Redis数据备份文件），也被叫做Redis数据快照。简单来说就是把内存中的所有数据都记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。快照文件称为RDB文件，默认是保存在当前运行目录。 <strong>RDB 文件的内容是二进制数据</strong></p><h4 id="_1-1-1-执行时机" tabindex="-1"><a class="header-anchor" href="#_1-1-1-执行时机"><span>1.1.1 执行时机</span></a></h4><p>RDB持久化在四种情况下会执行：</p><ul><li>执行save命令</li><li>执行bgsave命令</li><li>Redis停机时</li><li>触发RDB条件时</li></ul><p><strong>1）save命令</strong></p><p>执行下面的命令，可以立即执行一次RDB：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># redis-cli</span></span>\n<span class="line"><span>&gt; save #由Redis主进程来执行RDB，会阻塞所有命令</span></span>\n<span class="line"><span>ok</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长<strong>会阻塞主线程</strong>只有在数据迁移时可能用到。</p><p><strong>2）bgsave命令</strong></p><p>下面的命令可以异步执行RDB：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>127.0.0.1:6379&gt; bgsave # 开启子进程执行RDB 避免主进程受到影响</span></span>\n<span class="line"><span>Background saving started</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>会创建一个子进程来生成 RDB 文件，这样可以<strong>避免主线程的阻塞</strong>。</p><p><strong>3）停机时</strong></p><p>Redis停机时会执行一次save命令，实现RDB持久化。</p><p><strong>4）触发RDB条件</strong></p><p>Redis内部有触发RDB的机制，可以在redis.conf文件中找到，格式如下：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" data-title="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 900秒内，如果至少有1个key被修改，则执行bgsave ， 如果是save &quot;&quot; 则表示禁用RDB</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">save 900 1  </span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">save 300 10 </span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 代表60秒内至少执行1000次修改则触发RDB</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">save 60 10000</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>RDB的其它配置也可以在redis.conf文件中设置：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" data-title="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 是否压缩 ,建议不开启，压缩也会消耗cpu，磁盘的话不值钱</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">rdbcompression yes</span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># RDB文件名称</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">dbfilename dump.rdb  </span></span>\n<span class="line"></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 文件保存的路径目录</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">dir ./</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这里提一点，Redis 的快照是<strong>全量快照</strong>，也就是说每次执行快照，都是把内存中的「所有数据」都记录到磁盘中。</p><p>所以可以认为，执行快照是一个比较重的操作，如果频率太频繁，可能会对 Redis 性能产生影响。如果频率太低，服务器故障时，丢失的数据会更多。</p><p>通常可能设置至少 5 分钟才保存一次快照，这时如果 Redis 出现宕机等情况，则意味着最多可能丢失 5 分钟数据。</p><p>这就是 RDB 快照的缺点，在服务器发生故障时，丢失的数据会比 AOF 持久化的方式更多，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，而 AOF 日志可以以秒级的方式记录操作命令，所以丢失的数据就相对更少。</p><h4 id="_1-1-2-rdb原理" tabindex="-1"><a class="header-anchor" href="#_1-1-2-rdb原理"><span>1.1.2 RDB原理</span></a></h4><p>bgsave开始时会fork主进程得到子进程，子进程共享主进程的内存数据。完成fork后读取内存数据并写入 RDB 文件。</p><p>fork采用的是copy-on-write技术：</p><ul><li>执行 bgsave 命令的时候，会通过 <code>fork()</code> 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。</li><li>只有在发生修改内存数据的情况时，物理内存才会被复制一份。这样的目的是为了减少创建子进程时的性能损耗，从而加快创建子进程的速度，毕竟创建子进程的过程中，是会阻塞主线程的。</li><li>子线程完成RDB后 替换旧文件为新文件</li></ul><figure><img src="'+l+'" alt="image-20210725151319695" tabindex="0" loading="lazy"><figcaption>image-20210725151319695</figcaption></figure><p>bgsave 快照过程中，如果主线程修改了共享数据，<strong>发生了写时复制后，RDB 快照保存的是原本的内存数据</strong>，而主线程刚修改的数据，是没办法在这一时间写入 RDB 文件的，只能交由下一次的 bgsave 快照。</p><p>所以 Redis 在使用 bgsave 快照过程中，如果主线程修改了内存数据，不管是否是共享的内存数据，RDB 快照都无法写入主线程刚修改的数据，因为此时主线程（父进程）的内存数据和子进程的内存数据已经分离了，子进程写入到 RDB 文件的内存数据只能是原本的内存数据。</p><p>如果系统恰好在 RDB 快照文件创建完毕后崩溃了，那么 Redis 将会丢失主线程在快照期间修改的数据。</p><p>另外，写时复制的时候会出现这么个极端的情况。</p><p>在 Redis 执行 RDB 持久化期间，刚 fork 时，主进程和子进程共享同一物理内存，但是途中主进程处理了写操作，修改了共享内存，于是当前被修改的数据的物理内存就会被复制一份。</p><p>那么极端情况下，<strong>如果所有的共享内存都被修改，则此时的内存占用是原先的 2 倍。</strong></p><p>所以，针对写操作多的场景，我们要留意下快照过程中内存的变化，防止内存被占满了。</p><p>新写入的数据如果再次操作 是操作新的还是旧的：<strong>操作新的</strong></p><p>那么什么时候 将RDB过程中的操作数据写回磁盘：<strong>下次 RDB/AOF 持久化 或 正常淘汰</strong></p><h4 id="_1-1-3-总结" tabindex="-1"><a class="header-anchor" href="#_1-1-3-总结"><span>1.1.3 总结</span></a></h4><p>RDB方式bgsave的基本流程</p><figure><img src="'+t+'" alt="image-20210725151319695" tabindex="0" loading="lazy"><figcaption>image-20210725151319695</figcaption></figure><h3 id="_1-2-aof持久化" tabindex="-1"><a class="header-anchor" href="#_1-2-aof持久化"><span>1.2 AOF持久化</span></a></h3><h4 id="_1-2-1-aof原理" tabindex="-1"><a class="header-anchor" href="#_1-2-1-aof原理"><span>1.2.1 AOF原理</span></a></h4><p>AOF全称为Append Only File（追加文件）。Redis处理的每一个写命令都会记录在AOF文件，可以看做是命令日志文件。 <strong>AOF 文件的内容是操作命令</strong></p><p>AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" data-title="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 是否开启AOF功能，默认是no</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">appendonly yes</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># AOF文件的名称</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">appendfilename </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;appendonly.aof&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>AOF的命令记录的频率也可以通过redis.conf文件来配：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" data-title="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 表示每执行一次写命令，立即记录到AOF文件</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">appendfsync always </span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">appendfsync everysec </span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">appendfsync no</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>Redis 是先执行写操作命令后，才将该命令记录到 AOF 日志里的，这么做其实有两个好处。</p><p>第一个好处，<strong>避免额外的检查开销。</strong></p><p>因为如果先将写操作命令记录到 AOF 日志里，再执行该命令的话，如果当前的命令语法有问题，那么如果不进行命令语法检查，该错误的命令记录到 AOF 日志里后，Redis 在使用日志恢复数据时，就可能会出错。</p><p>而如果先执行写操作命令再记录日志的话，只有在该命令执行成功后，才将命令记录到 AOF 日志里，这样就不用额外的检查开销，保证记录在 AOF 日志里的命令都是可执行并且正确的。</p><p>第二个好处，<strong>不会阻塞当前写操作命令的执行</strong>，因为当写操作命令执行成功后，才会将命令记录到 AOF 日志。</p><p>当然，AOF 持久化功能也不是没有潜在风险。</p><p>第一个风险，执行写操作命令和记录日志是两个过程，那当 Redis 在还没来得及将命令写入到硬盘时，服务器发生宕机了，这个数据就会有<strong>丢失的风险</strong>。</p><p>第二个风险，前面说道，由于写操作命令执行成功后才记录到 AOF 日志，所以不会阻塞当前写操作命令的执行，但是<strong>可能会给「下一个」命令带来阻塞风险</strong>。</p><p>因为将命令写入到日志的这个操作也是在主进程完成的（执行命令也是在主进程），也就是说这两个操作是同步的。</p><figure><img src="'+p+'" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>如果在将日志内容写入到硬盘时，服务器的硬盘的 I/O 压力太大，就会导致写硬盘的速度很慢，进而阻塞住了，也就会导致后续的命令无法执行。</p><p>认真分析一下，其实这两个风险都有一个共性，都跟「 AOF 日志写回硬盘的时机」有关。</p><p><strong>Redis 写入 AOF 日志的过程</strong>：</p><ol><li>Redis 执行完写操作命令后，会将命令追加到 <code>server.aof_buf</code> 缓冲区；</li><li>然后通过 write() 系统调用，将 aof_buf 缓冲区的数据写入到 AOF 文件，此时数据并没有写入到硬盘，而是拷贝到了内核缓冲区 page cache，等待内核将数据写入硬盘；</li><li>具体内核缓冲区的数据什么时候写入到硬盘，由内核决定。</li></ol><p>三种<strong>写回策略</strong>对比：</p><figure><img src="'+r+'" alt="image-20210725151654046" tabindex="0" loading="lazy"><figcaption>image-20210725151654046</figcaption></figure><p>这 3 种写回策略都无法能完美解决「主进程阻塞」和「减少数据丢失」的问题，因为两个问题是对立的，偏向于一边的话，就会要牺牲另外一边，原因如下：</p><ul><li>Always 策略的话，可以最大程度保证数据不丢失，但是由于它每执行一条写操作命令就同步将 AOF 内容写回硬盘，所以是不可避免会影响主进程的性能；</li><li>No 策略的话，是交由操作系统来决定何时将 AOF 日志内容写回硬盘，相比于 Always 策略性能较好，但是操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。</li><li>Everysec 策略的话，是折中的一种方式，避免了 Always 策略的性能开销，也比 No 策略更能避免数据丢失，当然如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。</li></ul><p>大家根据自己的<strong>业务场景</strong>进行选择：</p><ul><li>如果要高性能，就选择 No 策略；</li><li>如果要高可靠，就选择 Always 策略；</li><li>如果允许数据丢失一点，但又想性能高，就选择 Everysec 策略。</li></ul><p>深入到源码后，你就会发现这三种策略只是在控制 <code>fsync()</code> 函数的调用时机。</p><p>当应用程序向文件写入数据时，内核通常先将数据复制到内核缓冲区中，然后排入队列，然后由内核决定何时写入硬盘。</p><p>如果想要应用程序向文件写入数据后，能立马将数据同步到硬盘，就可以调用 <code>fsync()</code> 函数，这样内核就会将内核缓冲区的数据直接写入到硬盘，等到硬盘写操作完成后，该函数才会返回。</p><ul><li>Always 策略就是每次写入 AOF 文件数据后，就执行 fsync() 函数；</li><li>Everysec 策略就会创建一个异步任务来执行 fsync() 函数；</li><li>No 策略就是永不执行 fsync() 函数;</li></ul><h4 id="_1-2-2-aof重写" tabindex="-1"><a class="header-anchor" href="#_1-2-2-aof重写"><span>1.2.2 AOF重写</span></a></h4><p>因为是记录命令，AOF文件会比RDB文件大的多。而且AOF会记录对同一个key的多次写操作，但只有最后一次写操作才有意义。通过执行bgrewriteaof命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果。其本意就是<strong>压缩AOF文件 减小内存占用</strong></p><figure><img src="'+d+'" alt="image-20210725151729118" tabindex="0" loading="lazy"><figcaption>image-20210725151729118</figcaption></figure><p>如图，AOF原本有三个命令，但是<code>set num 123 和 set num 666</code>都是对num的操作，第二次会覆盖第一次的值，因此第一个命令记录下来没有意义。</p><p>所以重写命令后，AOF文件内容就是：<code>mset name jack num 666</code></p><p>Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：</p><div class="language-properties line-numbers-mode" data-highlighter="shiki" data-ext="properties" data-title="properties" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># AOF文件比上次文件 增长超过多少百分比则触发重写</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">auto-aof-rewrite-percentage 100</span></span>\n<span class="line"><span style="--shiki-light:#A0A1A7;--shiki-dark:#7F848E;--shiki-light-font-style:italic;--shiki-dark-font-style:italic;"># AOF文件体积最小多大以上才触发重写 </span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#98C379;">auto-aof-rewrite-min-size 64mb</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>因为<strong>如果 AOF 重写过程中失败了，现有的 AOF 文件就会造成污染</strong>，可能无法用于恢复使用。</p><p>所以 AOF 重写过程，先重写到新的 AOF 文件，重写失败的话，就直接删除这个文件就好，不会对现有的 AOF 文件造成影响。</p><p><strong>AOF重写流程</strong>：</p><p>触发重写机制后，主进程就会创建重写 AOF 的子进程，此时父子进程共享物理内存，重写子进程只会对这个内存进行只读，重写 AOF 子进程会读取数据库里的所有数据，并逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志（新的 AOF 文件）。</p><p>但是子进程重写过程中，主进程依然可以正常处理命令。</p><p>如果此时主进程修改了已经存在 key-value，就会发生<strong>写时复制，注意这里只会复制主进程修改的物理内存数据，没修改物理内存还是与子进程共享的</strong>。</p><p>所以如果这个阶段修改的是一个 bigkey，也就是数据量比较大的 key-value 的时候，这时复制的物理内存数据的过程就会比较耗时，有阻塞主进程的风险。</p><p>还有个问题，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，此时这个 key-value 数据在子进程的内存数据就跟主进程的内存数据不一致了，这时要怎么办呢？</p><p>为了解决这种数据不一致问题，Redis 设置了一个 <strong>AOF 重写缓冲区</strong>，这个缓冲区在创建 bgrewriteaof 子进程之后开始使用。</p><p>在重写 AOF 期间，当 Redis 执行完一个写命令之后，它会<strong>同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」</strong>。</p><p>也就是说，在 bgrewriteaof 子进程执行 AOF 重写期间，主进程需要执行以下三个工作:</p><ul><li>执行客户端发来的命令；</li><li>将执行后的写命令追加到 「AOF 缓冲区」；</li><li>将执行后的写命令追加到 「AOF 重写缓冲区」；</li></ul><p>当子进程完成 AOF 重写工作（<em>扫描数据库中所有数据，逐一把内存数据的键值对转换成一条命令，再将命令记录到重写日志</em>）后，会向主进程发送一条信号，信号是进程间通讯的一种方式，且是异步的。</p><p>主进程收到该信号后，会调用一个信号处理函数，该函数主要做以下工作：</p><ul><li>将 AOF 重写缓冲区中的所有内容追加到新的 AOF 的文件中，使得新旧两个 AOF 文件所保存的数据库状态一致；</li><li>新的 AOF 的文件进行改名，覆盖现有的 AOF 文件。</li></ul><p>信号函数执行完后，主进程就可以继续像往常一样处理命令了。</p><p>在整个 AOF 后台重写过程中，除了发生写时复制会对主进程造成阻塞，还有信号处理函数执行时也会对主进程造成阻塞，在其他时候，AOF 后台重写都不会阻塞主进程。</p><h4 id="_1-2-3-总结" tabindex="-1"><a class="header-anchor" href="#_1-2-3-总结"><span><strong>1.2.3 总结</strong></span></a></h4><p>Redis 提供了三种将 AOF 日志写回硬盘的策略，分别是 Always、Everysec 和 No，这三种策略在可靠性上是从高到低，而在性能上则是从低到高。</p><p>随着执行的命令越多，AOF 文件的体积自然也会越来越大，为了避免日志文件过大， Redis 提供了 AOF 重写机制，它会直接扫描数据中所有的键值对数据，然后为每一个键值对生成一条写操作命令，接着将该命令写入到新的 AOF 文件，重写完成后，就替换掉现有的 AOF 日志。重写的过程是由后台子进程完成的，这样可以使得主进程可以继续正常处理命令。</p><p>用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了。</p><h3 id="_1-3-rdb和aof-混合" tabindex="-1"><a class="header-anchor" href="#_1-3-rdb和aof-混合"><span>1.3 RDB和AOF 混合</span></a></h3><p>尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：</p><ul><li>如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；</li><li>如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。</li></ul><p>那有没有什么方法不仅有 RDB 恢复速度快的优点和，又有 AOF 丢失数据少的优点呢？</p><p>当然有，那就是将 RDB 和 AOF 合体使用，这个方法是在 Redis 4.0 提出的，该方法叫<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化。</p><p>如果想要开启混合持久化功能，可以在 Redis 配置文件将下面这个配置项设置成 yes：</p><div class="language-text line-numbers-mode" data-highlighter="shiki" data-ext="text" data-title="text" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>aof-use-rdb-preamble yes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>混合持久化工作在 <strong>AOF 日志重写过程</strong>。</p><p>当开启了混合持久化时，在 AOF 重写日志时，<code>fork</code> 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p><p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据</strong>。</p><p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p><p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失</strong>。</p><h4 id="_1-3-1-rdb与aof对比" tabindex="-1"><a class="header-anchor" href="#_1-3-1-rdb与aof对比"><span>1.3.1 RDB与AOF对比</span></a></h4><p>RDB和AOF各有自己的优缺点，如果对数据安全性要求较高，在实际开发中往往会<strong>结合</strong>两者来使用。</p><figure><img src="'+h+'" alt="image-20210725151940515" tabindex="0" loading="lazy"><figcaption>image-20210725151940515</figcaption></figure><h2 id="_2-redis主从" tabindex="-1"><a class="header-anchor" href="#_2-redis主从"><span>2 Redis主从</span></a></h2><h3 id="_2-1-搭建主从架构" tabindex="-1"><a class="header-anchor" href="#_2-1-搭建主从架构"><span>2.1 搭建主从架构</span></a></h3><p>单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离。</p><figure><img src="'+g+'" alt="image-20210725152037611" tabindex="0" loading="lazy"><figcaption>image-20210725152037611</figcaption></figure><p>主从复制的作用主要包括：</p><ul><li><strong>数据冗余</strong>：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li><strong>故障恢复</strong>：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li><strong>高可用基石</strong>：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li></ul><p>主从库之间采用的是读写分离的方式。</p><ul><li>读操作：主库、从库都可以接收；</li><li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li></ul><h3 id="_2-2-主从数据同步原理" tabindex="-1"><a class="header-anchor" href="#_2-2-主从数据同步原理"><span>2.2 主从数据同步原理</span></a></h3><h4 id="_2-2-1-全量同步" tabindex="-1"><a class="header-anchor" href="#_2-2-1-全量同步"><span>2.2.1 全量同步</span></a></h4><p>主从第一次建立连接时，会执行<strong>全量同步</strong>，将master节点的所有数据都拷贝给slave节点，流程：</p><figure><img src="'+o+'" alt="image-20210725152222497" tabindex="0" loading="lazy"><figcaption>image-20210725152222497</figcaption></figure><p>这里有一个问题，master如何得知salve是第一次来连接呢？？</p><p>有几个概念，可以作为判断依据：</p><ul><li><strong>Replication Id</strong>：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid</li><li><strong>offset</strong>：偏移量，随着记录在repl_baklog中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset。如果slave的offset小于master的offset，说明slave数据落后于master，需要更新。</li></ul><p>因此slave做数据同步，必须向master声明自己的replication id 和offset，master才可以判断到底需要同步哪些数据。</p><p>因为slave原本也是一个master，有自己的replid和offset，当第一次变成slave，与master建立连接时，发送的replid和offset是自己的replid和offset。</p><p>master判断发现slave发送来的replid与自己的不一致，说明这是一个全新的slave，就知道要做全量同步了。</p><p>master会将自己的replid和offset都发送给这个slave，slave保存这些信息。以后slave的replid就与master一致了。</p><p>因此，<strong>master判断一个节点是否是第一次同步的依据，就是看replid是否一致</strong>。</p><p>如图：</p><figure><img src="'+c+'" alt="image-20210725152700914" tabindex="0" loading="lazy"><figcaption>image-20210725152700914</figcaption></figure><p>完整流程描述：</p><ul><li>slave节点请求增量同步</li><li>master节点判断replid，发现不一致，拒绝增量同步</li><li>master将完整内存数据生成RDB，发送RDB到slave</li><li>slave清空本地数据，加载master的RDB</li><li>master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave</li><li>slave执行接收到的命令，保持与master之间的同步</li></ul><figure><img src="'+k+'" alt="image-20210725152700914" tabindex="0" loading="lazy"><figcaption>image-20210725152700914</figcaption></figure><h4 id="_2-2-2-增量同步" tabindex="-1"><a class="header-anchor" href="#_2-2-2-增量同步"><span>2.2.2 增量同步</span></a></h4><p>全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做<strong>增量同步</strong>。</p><p>什么是增量同步？就是只更新slave与master存在差异的部分数据。如图：</p><figure><img src="'+u+'" alt="image-20210725153201086" tabindex="0" loading="lazy"><figcaption>image-20210725153201086</figcaption></figure><h4 id="_2-2-3-repl-backlog-buffer原理" tabindex="-1"><a class="header-anchor" href="#_2-2-3-repl-backlog-buffer原理"><span>2.2.3 repl_backlog_buffer原理</span></a></h4><p>master怎么知道slave与自己的数据差异在哪里呢?</p><p>这就要说到全量同步时的repl_baklog文件了。</p><p>这个文件是一个固定大小的数组，只不过数组是环形，也就是说<strong>角标到达数组末尾后，会再次从0开始读写</strong>，这样数组头部的数据就会被覆盖。</p><p>repl_baklog中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：</p><p>slave与master的offset之间的差异，就是salve需要增量拷贝的数据了。</p><p>随着不断有数据写入，master的offset逐渐变大，slave也不断的拷贝，追赶master的offset：</p><figure><img src="'+m+'" alt="image-20210725153524190" tabindex="0" loading="lazy"><figcaption>image-20210725153524190</figcaption></figure><p>直到数组被填满：</p><figure><img src="'+b+'" alt="image-20210725153715910" tabindex="0" loading="lazy"><figcaption>image-20210725153715910</figcaption></figure><p>此时，如果有新的数据写入，就会覆盖数组中的旧数据。不过，旧的数据只要是绿色的，说明是已经被同步到slave的数据，即便被覆盖了也没什么影响。因为未同步的仅仅是红色部分。</p><p>但是，如果slave出现网络阻塞，导致master的offset远远超过了slave的offset：</p><figure><img src="'+v+'" alt="image-20210725153937031" tabindex="0" loading="lazy"><figcaption>image-20210725153937031</figcaption></figure><p>如果master继续写入新数据，其offset就会覆盖旧的数据，直到将slave现在的offset也覆盖：</p><figure><img src="'+A+'" alt="image-20210725154155984" tabindex="0" loading="lazy"><figcaption>image-20210725154155984</figcaption></figure><p>棕色框中的红色部分，就是尚未同步，但是却已经被覆盖的数据。此时如果slave恢复，需要同步，却发现自己的offset都没有了，无法完成增量同步了。只能做全量同步。</p><figure><img src="'+f+'" alt="image-20210725154216392" tabindex="0" loading="lazy"><figcaption>image-20210725154216392</figcaption></figure><p><strong>replication buffer 和 repl_backlog_buffer 区别</strong></p><table><thead><tr><th></th><th>replication buffer</th><th>repl_backlog_buffer</th></tr></thead><tbody><tr><td>作用</td><td>主节点为<strong>每个从节点</strong>单独分配的缓冲区</td><td>主节点维护的<strong>全局环形缓冲区</strong>（所有从节点共享）</td></tr><tr><td>数据时效性</td><td>仅存全量同步期间的新命令</td><td>仅存全量同步期间的新命令</td></tr><tr><td>配置参数</td><td>根据从节点数调整 <code>client-output-buffer</code></td><td>根据从节点数调整 <code>client-output-buffer</code></td></tr><tr><td>意义</td><td>用于后续增量同步</td><td>用于全量同步</td></tr></tbody></table><h3 id="_2-3-主从同步优化" tabindex="-1"><a class="header-anchor" href="#_2-3-主从同步优化"><span>2.3 主从同步优化</span></a></h3><p>主从同步可以保证主从数据的一致性，非常重要。</p><p>可以从以下几个方面来优化Redis主从就集群：</p><ul><li>在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。</li><li>Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO</li><li>适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步</li><li>限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力</li></ul><p>主从从架构图：</p><figure><img src="'+y+'" alt="image-20210725154405899" tabindex="0" loading="lazy"><figcaption>image-20210725154405899</figcaption></figure><h2 id="_3-redis哨兵集群" tabindex="-1"><a class="header-anchor" href="#_3-redis哨兵集群"><span>3 Redis哨兵集群</span></a></h2><p>Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。</p><h3 id="_3-1-哨兵原理" tabindex="-1"><a class="header-anchor" href="#_3-1-哨兵原理"><span>3.1 哨兵原理</span></a></h3><h4 id="_3-1-1-集群结构和作用" tabindex="-1"><a class="header-anchor" href="#_3-1-1-集群结构和作用"><span>3.1.1 集群结构和作用</span></a></h4><p>哨兵的结构如图：</p><figure><img src="'+F+'" alt="image-20210725154528072" tabindex="0" loading="lazy"><figcaption>image-20210725154528072</figcaption></figure><p>哨兵的作用如下：</p><ul><li><strong>监控</strong>：Sentinel 会不断检查您的master和slave是否按预期工作</li><li><strong>自动故障恢复</strong>：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主</li><li><strong>通知</strong>：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis的客户端</li></ul><h4 id="_3-1-2-监控" tabindex="-1"><a class="header-anchor" href="#_3-1-2-监控"><span>3.1.2 监控</span></a></h4><p><strong>Sentinel 的本质</strong></p><p>Redis Sentinel（哨兵）是一个<strong>独立运行的进程</strong>，而不是Redis节点内部的线程或服务</p><p>推荐<strong>独立部署</strong>（不与Redis节点同机），但也可与Redis同机运行</p><p><strong>哨兵集群是如何组成的</strong></p><p>哨兵 A 把自己的 IP 地址和端口的信息发布到<code>__sentinel__:hello</code> 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。</p><p>正是通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了</p><p><strong>发现故障</strong></p><p>两个概念：主观下线和客观下线</p><ul><li><p><strong>主观下线</strong>：任何一个哨兵都是可以监控探测，并作出Redis节点下线的判断；</p><p>哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「<strong>主观下线</strong>」。这个「规定的时间」是配置项 <code>down-after-milliseconds</code> 参数设定的，单位是毫秒。</p><p>是的没错，<strong>客观下线只适用于主节点</strong>。</p><p>之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。</p><p>所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成<strong>哨兵集群</strong>（<em>最少需要三台机器来部署哨兵集群</em>），<strong>通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况</strong>。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。</p></li><li><p><strong>客观下线</strong>：由哨兵集群共同决定Redis节点是否下线；</p><p>当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。</p><p>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。</p><p>例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。</p><p>PS：quorum 的值一般设置为哨兵个数的二分之一加 1，例如 3 个哨兵就设置 2。</p><p>哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点</p></li></ul><p>当其中一个哨兵认为节点主观下线后，它会询问其他的哨兵，看其他节点是否也认为节点下线。如果接收到足够多的的数量证明节点下线，那么就会认为节点客观下线。具体的数量由下面的2来决定(配置文件中)。</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>sentine1 monitor mymaster 127.0.0.1 6379 2</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><figure><img src="'+B+'" alt="image-20210725154632354" tabindex="0" loading="lazy"><figcaption>image-20210725154632354</figcaption></figure><p><strong>哨兵选举</strong> 当有一个哨兵认为主节点客观下线，就会开始哨兵领头节点的选举。 为什么必然会出现选举/共识机制？ 故障的转移和通知都只需要一个主的哨兵节点就可以了。所以需要选<strong>举出一个执行通知和操作命令的哨兵</strong></p><p>哨兵的选举机制：就是一个<strong>Raft选举算法</strong>： 选举的票数大于等于num(sentinels)/2+1时，将成为领导者，如果没有超过，继续选举 任何一个想成为 Leader 的哨兵，要满足两个条件：</p><ul><li><p>第一，拿到半数以上的赞成票；</p></li><li><p>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。</p></li></ul><p>每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。</p><p>这也是为什么哨兵集群最少三个节点了 因为两个节点 如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。</p><p><strong>哨兵集群可以判定主节点“客观下线”</strong>。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。</p><p><strong>哨兵集群可以完成主从切换？</strong>。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，此哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件，所以就能选举成功，因此哨兵集群可以完成主从切换。 如果剩余两个哨兵则无法实现主从切换因为 无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到N/2+1选票的结果。</p><h4 id="_3-1-3-故障恢复" tabindex="-1"><a class="header-anchor" href="#_3-1-3-故障恢复"><span>3.1.3 故障恢复</span></a></h4><p>一旦发现master故障，sentinel需要在salve中选择一个作为新的master，选择依据是这样的：</p><ol><li><p><strong>选出新的主节点</strong></p><ol><li><p>首先<strong>过滤掉已经下线的和网络状态不好</strong>的：会判断 down-after-milliseconds * 10 配置项，其 down-after-milliseconds 是主从节点断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。</p></li><li><p>然后要对所有从节点进行<strong>三轮考察</strong>：<strong>优先级、复制进度、ID 号</strong>。在进行每一轮考察的时候，哪个从节点优先胜出：就选择其作为新主节点。判断slave节点的slave-priority值，越小优先级越高，如果是0则永不参与选举</p><ol><li><strong>第一轮考察：优先级最高的从节点胜出</strong> 哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前：Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。每一台从节点的服务器配置不一定是相同的，我们可以根据服务器性能配置来设置从节点的优先级。</li><li>**第二轮考察：复制进度最靠前的从节点胜出 **如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。判断slave节点的offset值，越大说明数据越新，优先级越高。</li><li>**第三轮考察：ID 号小的从节点胜出 **如果优先级和下标都相同，就选择从节点 ID 较小的那个。</li></ol></li></ol></li><li><p><strong>将从节点指向新主节点</strong></p><p>哨兵 leader 向所有从节点发送 <code>SLAVEOF</code>命令 ，让它们成为新主节点的从节点。</p></li><li><p><strong>通知客户的主节点已更换</strong></p><p>这主要<strong>通过 Redis 的发布者/订阅者机制来实现</strong>的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。哨兵提供的消息订阅频道有很多，不同频道包含了主从节点切换过程中的不同关键事件，几个常见的事件如下：</p><figure><img src="'+R+'" alt="image-20210725154632354" tabindex="0" loading="lazy"><figcaption>image-20210725154632354</figcaption></figure><p>客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。<strong>主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了</strong>。</p><p>通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。</p></li><li><p><strong>将旧主节点变为从节点</strong></p><p>故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 <code>SLAVEOF</code> 命令，让它成为新主节点的从节点</p><p>至此，整个主从节点的故障转移的工作结束</p></li></ol><figure><img src="'+_+'" alt="image-20210725154816841" tabindex="0" loading="lazy"><figcaption>image-20210725154816841</figcaption></figure><h3 id="_3-1-4-总结" tabindex="-1"><a class="header-anchor" href="#_3-1-4-总结"><span>3.1.4 总结</span></a></h3><p>Redis 在 2.8 版本以后提供的<strong>哨兵（Sentinel）机制</strong>，它的作用是实现<strong>主从节点故障转移</strong>。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。</p><p>哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：<strong>监控、选主、通知</strong>。</p><p>哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。</p><p><em>1、第一轮投票：判断主节点下线</em></p><p>当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。</p><p>当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。</p><p><em>2、第二轮投票：选出哨兵 leader</em></p><p>某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件：</p><ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul><p><em>3、由哨兵 leader 进行主从故障转移</em></p><p>选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤：</p><ul><li>第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则： <ul><li>过滤掉已经离线的从节点；</li><li>过滤掉历史网络连接状态不好的从节点；</li><li>将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。</li></ul></li><li>第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；</li><li>第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；</li><li>第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点；</li></ul><p>3.2 搭建哨兵集群</p><p>略 ~~</p><h3 id="_3-3-java配置哨兵集群" tabindex="-1"><a class="header-anchor" href="#_3-3-java配置哨兵集群"><span>3.3 java配置哨兵集群</span></a></h3><p>在Sentinel集群监管下的Redis主从集群，其节点会因为自动故障转移而发生变化，Redis的客户端必须感知这种变化，及时更新连接信息。Spring的RedisTemplate底层利用lettuce实现了节点的感知和自动切换。</p><p>下面，我们来实现RedisTemplate集成哨兵机制。</p><p><strong>引入依赖</strong></p><p>在项目的pom文件中引入依赖：</p><div class="language-xml line-numbers-mode" data-highlighter="shiki" data-ext="xml" data-title="xml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">dependency</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">groupId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;org.springframework.boot&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">groupId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    &lt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">artifactId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;spring-boot-starter-data-redis&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">artifactId</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&lt;/</span><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">dependency</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>配置Redis地址</strong></p><p>然后在配置文件application.yml中指定redis的sentinel相关信息：</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">spring</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">  redis</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">    sentinel</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">      master</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> mymaster</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">      nodes</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">        -</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 192.168</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">150</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">101</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">27001</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">        -</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 192.168</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">150</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">101</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">27002</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#56B6C2;">        -</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 192.168</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">150</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:white;--shiki-dark:#FFFFFF;">101</span><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">:</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">27003</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p><strong>配置读写分离</strong></p><p>在项目的启动类中，添加一个新的bean：</p><div class="language-java line-numbers-mode" data-highlighter="shiki" data-ext="java" data-title="java" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">@</span><span style="--shiki-light:#A626A4;--shiki-dark:#E5C07B;">Bean</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">public</span><span style="--shiki-light:#C18401;--shiki-dark:#E5C07B;"> LettuceClientConfigurationBuilderCustomizer</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;"> clientConfigurationBuilderCustomizer</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">(){</span></span>\n<span class="line"><span style="--shiki-light:#A626A4;--shiki-dark:#C678DD;">    return</span><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;"> clientConfigurationBuilder </span><span style="--shiki-light:#C18401;--shiki-dark:#C678DD;">-&gt;</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;"> clientConfigurationBuilder</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">readFrom</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">(</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">ReadFrom</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">.</span><span style="--shiki-light:#E45649;--shiki-dark:#E5C07B;">REPLICA_PREFERRED</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">);</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#E06C75;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这个bean中配置的就是读写策略，包括四种：</p><ul><li>MASTER：从主节点读取</li><li>MASTER_PREFERRED：优先从master节点读取，master不可用才读取replica</li><li>REPLICA：从slave（replica）节点读取</li><li>REPLICA _PREFERRED：优先从slave（replica）节点读取，所有的slave都不可用才读取master</li></ul><h2 id="_4-redis分片集群" tabindex="-1"><a class="header-anchor" href="#_4-redis分片集群"><span>4 Redis分片集群</span></a></h2><h3 id="_4-1-搭建分片集群" tabindex="-1"><a class="header-anchor" href="#_4-1-搭建分片集群"><span>4.1 搭建分片集群</span></a></h3><p>主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：</p><ul><li><p>海量数据存储问题</p></li><li><p>高并发写的问题</p></li></ul><p>使用分片集群可以解决上述问题，如图:</p><figure><img src="'+x+'" alt="image-20210725155747294" tabindex="0" loading="lazy"><figcaption>image-20210725155747294</figcaption></figure><p>分片集群特征：</p><ul><li><p>集群中有多个master，每个master保存不同数据</p></li><li><p>每个master都可以有多个slave节点</p></li><li><p>master之间通过ping监测彼此健康状态</p></li><li><p>客户端请求可以访问集群任意节点，最终都会被转发到正确节点</p></li></ul><h3 id="_4-2-散列插槽" tabindex="-1"><a class="header-anchor" href="#_4-2-散列插槽"><span>4.2 散列插槽</span></a></h3><h4 id="_4-2-1-插槽原理" tabindex="-1"><a class="header-anchor" href="#_4-2-1-插槽原理"><span>4.2.1 插槽原理</span></a></h4><p>Redis-cluster没有使用一致性hash，而是引入了哈希槽的概念。Redis-cluster中有16384(即2的14次方）个哈希槽，每个key通过<strong>CRC16</strong>校验后对16383取模来决定放置哪个槽。Cluster中的每个节点负责一部分hash槽（hash slot）。</p><p>Redis会把每一个master节点映射到0~16383共16384个插槽（hash slot）上，查看集群信息时就能看到：</p><figure><img src="'+O+'" alt="image-20210725155820320" tabindex="0" loading="lazy"><figcaption>image-20210725155820320</figcaption></figure><p>数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况：</p><ul><li>key中包含&quot;{}&quot;，且“{}”中至少包含1个字符，“{}”中的部分是有效部分</li><li>key中不包含“{}”，整个key都是有效部分</li></ul><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>set {activity}dudu:1314 &quot;dudu&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>存取原理：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>127.0.0.1:7001&gt; set a 1</span></span>\n<span class="line"><span>-&gt; Redirected to slot [15495] located at 192.168.150.101:7003</span></span>\n<span class="line"><span>OK</span></span>\n<span class="line"><span>192.168.150.101:7003&gt;</span></span>\n<span class="line"><span>get num</span></span>\n<span class="line"><span>-&gt; Redirected to slot [2765] located at 192.168.150.101:7001</span></span>\n<span class="line"><span>&quot;123&quot;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>在7001这个节点执行set a 1时，对a做hash运算，对16384取余，得到的结果是15495，因此要存储到103节点。</p><p>到了7003后，执行<code>get num</code>时，对num做hash运算，对16384取余，得到的结果是2765，因此需要切换到7001节点</p><h4 id="_4-2-2-一致性hash算法" tabindex="-1"><a class="header-anchor" href="#_4-2-2-一致性hash算法"><span>4.2.2 一致性hash算法</span></a></h4><p><strong>传统哈希的痛点</strong></p><p>假设用 <code>hash(key) % N</code> 分配数据到 N 个节点：</p><ol><li><strong>节点增删时</strong>：<code>N</code> 变化 → <strong>几乎所有数据需要重新分配</strong>（如 <code>N=100</code> 扩容到 <code>N=101</code>，99%的数据需迁移）</li><li><strong>雪崩效应</strong>：一个节点故障 → 缓存集体失效 → 数据库压力暴增</li></ol><p><strong>一致性hash的原理</strong></p><ol><li>把所有可能的哈希值想象成一个 “圆环”（比如范围 0~2³²-1，像一个首尾相接的圆圈）；</li><li>把每个 Redis 节点也通过哈希计算，“钉” 在这个圆环的某个位置上；</li><li>存储数据时，先对数据的键做哈希，也 “扔” 到圆环上，然后顺时针找最近的一个节点，就存在这个节点上。</li></ol><p>一致性hash将hash空间分为了一个环，每个数据计算出hash后，都会根据hash值，在环上找到对应的节点。</p><p>一致性 Hash 就是：将原本单个点的 Hash 映射，转变为了在一个环上的某个片段上的映射</p><p>优点：一致性hash的最大优点在于，扩缩容的时候，只会影响到环上的部分节点，不会像hash取模那样导致大面积的数据位置变动。它还可以通过增加虚拟节点解决节点不均衡的问题。 适用场景：一致性hash由于均衡的特性，非常适合在缓存和负载均衡的场景。</p><h4 id="_4-2-3-redis为什么用hash槽" tabindex="-1"><a class="header-anchor" href="#_4-2-3-redis为什么用hash槽"><span>4.2.3 Redis为什么用hash槽</span></a></h4><ul><li><strong>直观的管理</strong>：redis的hash槽，是需要用户手动去配置的，可以很直观的管理服务器和槽的关系。</li><li><strong>故障雪崩</strong>：一致性hash遇到了缩容场景，会自动将数据范围分配给其它节点。而redis的高可用是依赖的哨兵+主从。一个集群节点出现故障的时候，redis不会自动的修改槽的位置的，依赖从节点来代替主节点。如果用的一致性hash，一个节点挂了。那么那个节点所有的数据都失效了，都从其它的节点加载不到，请求全部打到数据库去了，产生缓存雪崩。如果用的是hash槽，那么依赖redis的高可用，从节点顶上来了，几乎所有的数据从节点都有，就不会产生雪崩了。</li><li><strong>数据的准确性</strong>：redis并不是存所有的缓存数据，很多时候也直接作为数据源使用。那么一台节点挂了，并不是靠一致性hash从另一个节点就能取到的。要么通过高可用，从从节点取到数据。要么宁愿不能用。后期通过rdb+aof做数据修复。通过固定的hash槽配置，才能精确的知道每个数据在哪个节点，而不是像一致性hash这样适应性的变来变去。</li></ul><h3 id="_4-3-集群伸缩" tabindex="-1"><a class="header-anchor" href="#_4-3-集群伸缩"><span>4.3 集群伸缩</span></a></h3><p>redis-cli --cluster提供了很多操作集群的命令，可以通过下面方式查看：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># redis-cli --cluster help</span></span>\n<span class="line"><span>// 添加节点命令</span></span>\n<span class="line"><span>add-node    new_host:new_port existing_ host:existing_port</span></span>\n<span class="line"><span>--cluster-slave</span></span>\n<span class="line"><span>cluster-master-id &lt;arg&gt;</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>下面我们实操一下吧</p><h4 id="_4-3-1-添加新节点到redis" tabindex="-1"><a class="header-anchor" href="#_4-3-1-添加新节点到redis"><span>4.3.1 添加新节点到redis</span></a></h4><p>执行命令：</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">redis-cli</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --cluster</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> add-node</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">  192.168.150.101:7004</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> 192.168.150.101:7001</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>通过命令查看集群状态：</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" data-title="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">redis-cli</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -p</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 7001</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> cluster</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> nodes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>如图，7004加入了集群，并且默认是一个master节点：</p><figure><img src="'+D+'" alt="image-20210725161007099" tabindex="0" loading="lazy"><figcaption>image-20210725161007099</figcaption></figure><p>但是，可以看到7004节点的插槽数量为0，因此没有任何数据可以存储到7004上</p><h4 id="_4-3-2-手动转移插槽" tabindex="-1"><a class="header-anchor" href="#_4-3-2-手动转移插槽"><span>4.3.2 手动转移插槽</span></a></h4><p>比如我们可以将0~3000的插槽从7001转移到7004，命令格式如下：</p><p>具体命令如下：</p><p>建立连接：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span># 将7001节点从新分配hash槽</span></span>\n<span class="line"><span>redis-cli --cluster reshard 192.0.0.1:7001</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><p>得到下面的反馈：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>[OK] All nodes agree about slots configuration.</span></span>\n<span class="line"><span>&gt;&gt;&gt; Check for open slots..</span></span>\n<span class="line"><span>&gt;&gt;&gt; Check slots coverage...</span></span>\n<span class="line"><span>[OK] All 16384 slots covered.</span></span>\n<span class="line"><span>// 询问要移动多少个插槽，我们计划是3000个</span></span>\n<span class="line"><span>How many slots do you want to move (from 1 to 16384)? 3000</span></span>\n<span class="line"><span>// 然后查询我们分配的节点的id</span></span>\n<span class="line"><span>What is the receiving node ID? 60826ce0ba7belf71b6dob9fd28f75953e742312</span></span>\n<span class="line"><span>Please enter all the source node IDs</span></span>\n<span class="line"><span>Type &#39;all&#39; to use all the nodes as source nodes for the hash slots.</span></span>\n<span class="line"><span>Type &#39;done&#39; once you entered all the source nodes IDs.</span></span>\n<span class="line"><span>// 这里询问，你的插槽是从哪里移动过来的 我们填写7001的id</span></span>\n<span class="line"><span>- all：代表全部，也就是三个节点各转移一部分</span></span>\n<span class="line"><span>- 具体的id：目标节点的id</span></span>\n<span class="line"><span>- done：没有了</span></span>\n<span class="line"><span>Source node #1: asdfasohret9gw90urtg245hw59urg9w3845y</span></span>\n<span class="line"><span>// 剩下的填done</span></span>\n<span class="line"><span>Source node #2: done</span></span>\n<span class="line"><span>// 确认要转移吗？输入yes：</span></span>\n<span class="line"><span>Do you want to proceedwith the proposed reshard plan (ves/no)? yes</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>然后，通过命令查看结果：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" data-title="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>redis-cli -p 7001 cluster node</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>可以看到：</p><figure><img src="'+C+'" alt="image-20210725162224058" tabindex="0" loading="lazy"><figcaption>image-20210725162224058</figcaption></figure><p>目的达成。</p><h4 id="_4-3-3-请求重定向" tabindex="-1"><a class="header-anchor" href="#_4-3-3-请求重定向"><span>4.3.3 请求重定向</span></a></h4><p>由于集群节点会出现伸缩，有可能我们记录的槽和集群的映射关系已经过时了，这时候我们如何访问到准确的集群节点呢？这就依赖了moved重定向和ask重定向</p><p><strong>MOVED 重定向</strong></p><p>前键命令所请求的键不在当前请求的节点中，则当前节点会向客户端发送一个Moved 重定向，客户端根据Moved 重定向所包含的内容找到目标节点，再一次发送命令。</p><p><strong>ASK 重定向</strong></p><p>Ask重定向发生于集群伸缩时，集群伸缩会导致槽迁移，当我们去源节点访问时，此时数据已经可能已经迁移到了目标节点，使用Ask重定向来解决此种情况。</p><ul><li>当A节点该Slot槽设置为 MIGRATING迁出状态 后，A节点依然可以接受有关此Slot槽的查询命令。如果该Key依然存在于该Slot槽中，则直接返回结果；如果该Key不存在于该Slot槽，说明该Key可能已经迁移到目的节点B当中了，故其会返回ASK重定向以告知客户端该Slot槽迁入的目的节点B地址信息</li><li>当B节点该Slot槽设置为 IMPORTING迁入状态 时，B节点可以接受有关此哈希槽的查询命令。但前提是客户端向B节点发送该Key的查询命令之前，必须要先发送ASKING命令。否则，B节点会返回MOVED重定向以告知客户端A节点的地址信息</li></ul><p>在伸缩期间，如果重定向不带Asking的话，请求会直接被拒绝的 这样也就是在迁移期间，所有请求都必须先请求Source再请求destination，这样能保证一致.</p><h3 id="_4-4-故障转移" tabindex="-1"><a class="header-anchor" href="#_4-4-故障转移"><span>4.4 故障转移</span></a></h3><h4 id="_4-4-1-自动故障转移" tabindex="-1"><a class="header-anchor" href="#_4-4-1-自动故障转移"><span>4.4.1 自动故障转移</span></a></h4><p>当slave发现自己的master变成Fail状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave。Failover的过程需要经过类Raft协议的过程在整个集群内达到一致， 其过程如下：</p><ol><li>slave发现自己的master变为FAIL</li><li>将自己记录的集群currentEpoch加1，并广播Failover Request信息</li><li>其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack</li><li>尝试failover的slave收集FAILOVER_AUTH_ACK</li><li>超过半数后变成新Master</li><li>广播Pong通知其他集群节点</li></ol><blockquote><p>哨兵模式是哨兵请求选举，得到超过半数哨兵的支持，然后领头哨兵选举从节点晋升。 集群模式是从节点请求超过半数的集群节点支持，自己主动晋升</p></blockquote><h4 id="_4-4-2-手动故障转移" tabindex="-1"><a class="header-anchor" href="#_4-4-2-手动故障转移"><span>4.4.2 手动故障转移</span></a></h4><p>利用cluster failover命令可以手动让集群中的某个master宕机，切换到执行cluster failover命令的这个slave节点，实现无感知的数据迁移。其流程如下：</p><figure><img src="'+E+'" alt="image-20210725162441407" tabindex="0" loading="lazy"><figcaption>image-20210725162441407</figcaption></figure><p>这种failover命令可以指定三种模式：</p><ul><li>缺省：默认的流程，如图1~6歩</li><li>force：省略了对offset的一致性校验</li><li>takeover：直接执行第5歩，忽略数据一致性、忽略master状态和其它master的意见</li></ul><h3 id="_4-5-cluster模式和proxy模式" tabindex="-1"><a class="header-anchor" href="#_4-5-cluster模式和proxy模式"><span>4.5 Cluster模式和Proxy模式</span></a></h3><p>集群是通过水平扩容来解决，数据量过大，或者并发太高的问题，水平扩容后，数据该落在哪，去哪查，就由集群来决定。redis的集群方案主要有两种，就是Proxy和Cluster。</p><h4 id="_4-5-1-proxy模式" tabindex="-1"><a class="header-anchor" href="#_4-5-1-proxy模式"><span>4.5.1 proxy模式</span></a></h4><p>就是引入中间层来管理水平扩容的多个redis节点。常见的实现有twemproxy和codis。</p><p>优点：</p><ol><li>客户端只需要连几个有限的proxy节点，实现简单</li><li>proxy对外隐藏了集群的规模和细节，客户端使用无感，和之前一样。</li></ol><p>缺点：</p><ol><li><p>多了一层proxy的网络开销，性能有影响</p></li><li><p>所有的复杂度都移到了proxy中，需要proxy保证高可用，对proxy要求很高。</p></li><li><p>需要额外的服务器资源去部署proxy</p></li></ol><h4 id="_4-5-2-cluster模式" tabindex="-1"><a class="header-anchor" href="#_4-5-2-cluster模式"><span>4.5.2 cluster模式</span></a></h4><p>cluster模式是redis3.0开始推出的集群方案，但是没有严格测试和生产验证，后期迭代后才开始被更多人接受。</p><p>Redis官方推出的Redis Cluster另辟蹊径，它没有采用中心化模式的Proxy方案，而是把请求转发逻辑一部分放在客户端，一部分放在了服务端，它们之间互相配合完成请求的处理。</p><p>优点：</p><ol><li>客户端直连redis节点，性能更好</li></ol><p>缺点：</p><ol><li><p>需要客户端额外的编写一些逻辑，比如保存节点映射信息，请求转发逻辑（sdk帮我们实现了）</p></li><li><p>客户端需要保存所有集群节点信息，集群比较大的时候100-200个master时，数据量会比较大。</p></li><li><p>集群间的节点需要互相ping pong，在节点多的时候网络开销比较大</p></li></ol><p><strong>怎么选择？</strong></p><p>（这个选择有关于优缺点，也有历史背景）</p><p>在redis3.0才出来的cluster模式，以及到后面才开始慢慢热门起来。所以在热门之前，基本都是靠codis来实现的集群 ，老一些的公司就一直沿用了codis。</p><p>所以现在如果没有什么其他的原因，我们最好都直接用cluster模式，官方原生支持，不需要额外的proxy中间件，不需要额外的服务器资源部署这一套，也不会有额外的网络调用消耗，不会引入额外的风险。</p><p>除非集群数量过大，用cluster模式达到客户端存储或者集群间心跳的瓶颈，可以考虑用codis以及改造codis。</p><h3 id="_4-6-redistemplate访问分片集群" tabindex="-1"><a class="header-anchor" href="#_4-6-redistemplate访问分片集群"><span>4.6 RedisTemplate访问分片集群</span></a></h3><p>RedisTemplate底层同样基于lettuce实现了分片集群的支持，而使用的步骤与哨兵模式基本一致：</p><p>1）引入redis的starter依赖</p><p>2）配置分片集群地址</p><p>3）配置读写分离</p><p>与哨兵模式相比，其中只有分片集群的配置方式略有差异，如下：</p><div class="language-yaml line-numbers-mode" data-highlighter="shiki" data-ext="yaml" data-title="yaml" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">spring</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">  redis</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">    cluster</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">      nodes</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:7001</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:7002</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:7003</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:8001</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:8002</span></span>\n<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">        - </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">192.168.150.101:8003</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>',333),S={},P=(0,e(6262).A)(S,[["render",function(i,s){return(0,a.uX)(),(0,a.CE)("div",null,[w,I,(0,a.Q3)(" more "),z])}]]),q=JSON.parse('{"path":"/program/redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html","title":"Redis持久化分布式缓存","lang":"zh-CN","frontmatter":{"totail":null,"icon":"book","date":"2023-10-01T00:00:00.000Z","category":["编程"],"tag":["Redis"],"description":"AOF|RDB、主从搭建、哨兵集群、分片集群根本学不完。。。","head":[["meta",{"property":"og:url","content":"https://github.com/DUDU-dudu-DUDU/xwblog/xwblog/program/redis/Redis%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98.html"}],["meta",{"property":"og:site_name","content":"小吴 Blog"}],["meta",{"property":"og:title","content":"Redis持久化分布式缓存"}],["meta",{"property":"og:description","content":"AOF|RDB、主从搭建、哨兵集群、分片集群根本学不完。。。"}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-12T12:50:47.000Z"}],["meta",{"property":"article:author","content":"xiaowu"}],["meta",{"property":"article:tag","content":"Redis"}],["meta",{"property":"article:published_time","content":"2023-10-01T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-12T12:50:47.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Redis持久化分布式缓存\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-10-01T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-12T12:50:47.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"xiaowu\\",\\"url\\":\\"https://dudu-dudu-dudu.github.io/xwblog/zh/\\"}]}"]]},"headers":[{"level":2,"title":"1  Redis持久化","slug":"_1-redis持久化","link":"#_1-redis持久化","children":[{"level":3,"title":"1.1 RDB持久化","slug":"_1-1-rdb持久化","link":"#_1-1-rdb持久化","children":[]},{"level":3,"title":"1.2 AOF持久化","slug":"_1-2-aof持久化","link":"#_1-2-aof持久化","children":[]},{"level":3,"title":"1.3 RDB和AOF 混合","slug":"_1-3-rdb和aof-混合","link":"#_1-3-rdb和aof-混合","children":[]}]},{"level":2,"title":"2 Redis主从","slug":"_2-redis主从","link":"#_2-redis主从","children":[{"level":3,"title":"2.1 搭建主从架构","slug":"_2-1-搭建主从架构","link":"#_2-1-搭建主从架构","children":[]},{"level":3,"title":"2.2 主从数据同步原理","slug":"_2-2-主从数据同步原理","link":"#_2-2-主从数据同步原理","children":[]},{"level":3,"title":"2.3 主从同步优化","slug":"_2-3-主从同步优化","link":"#_2-3-主从同步优化","children":[]}]},{"level":2,"title":"3 Redis哨兵集群","slug":"_3-redis哨兵集群","link":"#_3-redis哨兵集群","children":[{"level":3,"title":"3.1 哨兵原理","slug":"_3-1-哨兵原理","link":"#_3-1-哨兵原理","children":[]},{"level":3,"title":"3.1.4 总结","slug":"_3-1-4-总结","link":"#_3-1-4-总结","children":[]},{"level":3,"title":"3.3 java配置哨兵集群","slug":"_3-3-java配置哨兵集群","link":"#_3-3-java配置哨兵集群","children":[]}]},{"level":2,"title":"4 Redis分片集群","slug":"_4-redis分片集群","link":"#_4-redis分片集群","children":[{"level":3,"title":"4.1 搭建分片集群","slug":"_4-1-搭建分片集群","link":"#_4-1-搭建分片集群","children":[]},{"level":3,"title":"4.2 散列插槽","slug":"_4-2-散列插槽","link":"#_4-2-散列插槽","children":[]},{"level":3,"title":"4.3 集群伸缩","slug":"_4-3-集群伸缩","link":"#_4-3-集群伸缩","children":[]},{"level":3,"title":"4.4 故障转移","slug":"_4-4-故障转移","link":"#_4-4-故障转移","children":[]},{"level":3,"title":"4.5 Cluster模式和Proxy模式","slug":"_4-5-cluster模式和proxy模式","link":"#_4-5-cluster模式和proxy模式","children":[]},{"level":3,"title":"4.6 RedisTemplate访问分片集群","slug":"_4-6-redistemplate访问分片集群","link":"#_4-6-redistemplate访问分片集群","children":[]}]}],"git":{"createdTime":1755003047000,"updatedTime":1755003047000,"contributors":[{"name":"DUDU","email":"930824238@qq.com","commits":1}]},"readingTime":{"minutes":44.4,"words":13321},"filePathRelative":"program/redis/Redis分布式缓存.md","localizedDate":"2023年10月1日","excerpt":"\\n<p>AOF|RDB、主从搭建、哨兵集群、分片集群根本学不完。。。</p>\\n","autoDesc":true}')}}]);